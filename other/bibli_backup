%**** Motivation *****
% Bridge Inspection UAV
@inproceedings{nikolic2013uav,
  title={A UAV system for inspection of industrial facilities},
  author={Nikolic, Janosch and Burri, Michael and Rehder, Joern and Leutenegger, Stefan and Huerzeler, Christoph and Siegwart, Roland},
  booktitle={2013 IEEE Aerospace Conference},
  pages={1--8},
  year={2013},
  organization={IEEE}
}

%**** RL *****
% Reinforcement Learning Book
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}
% Mountian Car Problem
@article{singh1996reinforcement,
  title={Reinforcement learning with replacing eligibility traces},
  author={Singh, Satinder P and Sutton, Richard S},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={123--158},
  year={1996},
  publisher={Springer}
}
% ****** Policy Search**********
% CMA
@article{hansen2001completely,
  title={Completely derandomized self-adaptation in evolution strategies},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary computation},
  volume={9},
  number={2},
  pages={159--195},
  year={2001},
  publisher={MIT Press}
}
% Deterministic Gradient Algorithm Explainations
@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}
% ******* Policy Iteration**********
% Q-learning
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}
% ****** Policy Optimization ******
% PPO
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
% Deep-Q Famous Nature Paper
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}
% DDPG Continuous Learning after Nature Paper
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
% TRPO
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

% **** RL in Control ****
% Helicopter RL Paper
@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental Robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}

% Robotics survey
@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
% ****Reinforcement learning on Quadrotors******
% ETH Zurich RL Quad Paper
@article{hwangbo2017control,
  title={Control of a quadrotor with reinforcement learning},
  author={Hwangbo, Jemin and Sa, Inkyu and Siegwart, Roland and Hutter, Marco},
  journal={IEEE Robotics and Automation Letters},
  volume={2},
  number={4},
  pages={2096--2103},
  year={2017},
  publisher={IEEE}
}
% Neuroflight Paper
@article{koch2019neuroflight,
  title={Neuroflight: Next Generation Flight Control Firmware},
  author={Koch, William and Mancuso, Renato and Bestavros, Azer},
  journal={arXiv preprint arXiv:1901.06553},
  year={2019}
}
% GymFC Paper
@misc{1804.04154,
Author = {William Koch and Renato Mancuso and Richard West and Azer Bestavros},
Title = {Reinforcement Learning for UAV Attitude Control},
Year = {2018},
Eprint = {arXiv:1804.04154},
}
% 2010 RL on quadrotor Model
@inproceedings{bou2010controller,
  title={Controller design for quadrotor uavs using reinforcement learning},
  author={Bou-Ammar, Haitham and Voos, Holger and Ertel, Wolfgang},
  booktitle={2010 IEEE International Conference on Control Applications},
  pages={2130--2135},
  year={2010},
  organization={IEEE}
}
% 2012 Experimental Validation
@inproceedings{santos2012experimental,
 title={An Experimental Validation of Reinforcement Learning Applied to the Position Control of UAVs},
 author={S\'ergio Ronaldo Barros dos Santos, Sidney N. Givigi Jr., Cairo L\'ucio Nascimento J\'unior},
 year={2012},
 organization={IEEE},
 booktitle={2012 IEEE International Conference on Systems, Man, and Cybernetics}
}
% Outer Loop RL learning for UAV acrobatics
@inproceedings{lupashin2010simple,
  title={A simple learning strategy for high-speed quadrocopter multi-flips},
  author={Lupashin, Sergei and Sch{\"o}llig, Angela and Sherback, Michael and D'Andrea, Raffaello},
  booktitle={2010 IEEE International Conference on Robotics and Automation},
  pages={1642--1648},
  year={2010},
  organization={IEEE}
}

% **** Controls ******
% Mathematical Model of quadrotor
@inproceedings{bouabdallah2004design,
  title={Design and control of an indoor micro quadrotor},
  author={Bouabdallah, Samir and Murrieri, Pierpaolo and Siegwart, Roland},
  booktitle={IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA'04. 2004},
  volume={5},
  pages={4393--4398},
  year={2004},
  organization={IEEE}
}

% Robust PID Quadrotor
@article{garcia2012robust,
  title={Robust PID control of the quadrotor helicopter},
  author={Garcia, RA and Rubio, FR and Ortega, MG},
  journal={IFAC Proceedings Volumes},
  volume={45},
  number={3},
  pages={229--234},
  year={2012},
  publisher={Elsevier}
}

% nonlinear control of quadrotor
@inproceedings{voos2009nonlinear,
  title={Nonlinear control of a quadrotor micro-UAV using feedback-linearization},
  author={Voos, Holger},
  booktitle={2009 IEEE International Conference on Mechatronics},
  pages={1--6},
  year={2009},
  organization={IEEE}
}

% ***** Quadrotors *****
% Aerial robotics platform
@article{lupashin2014platform,
  title={A platform for aerial robotics research and demonstration: The flying machine arena},
  author={Lupashin, Sergei and Hehn, Markus and Mueller, Mark W and Schoellig, Angela P and Sherback, Michael and D’Andrea, Raffaello},
  journal={Mechatronics},
  volume={24},
  number={1},
  pages={41--54},
  year={2014},
  publisher={Elsevier}
}
% **** MLC ******
% Machine Learning Control
@book{duriez2017machine,
  title={Machine Learning Control-Taming Nonlinear Dynamics and Turbulence},
  author={Duriez, Thomas and Brunton, Steven L and Noack, Bernd R},
  volume={116},
  year={2017},
  publisher={Springer}
}
%***** AI and Applications ******
% AI Definition
@article{kaplan2019siri,
  title={Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence},
  author={Kaplan, Andreas and Haenlein, Michael},
  journal={Business Horizons},
  volume={62},
  number={1},
  pages={15--25},
  year={2019},
  publisher={Elsevier}
}
% IBM Watson (Real World Example)
@article{high2012era,
  title={The era of cognitive systems: An inside look at IBM Watson and how it works},
  author={High, Rob},
  journal={IBM Corporation, Redbooks},
  year={2012}
}
% AlphaGo
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}
% Google Translate
@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}
% RL for Neural Machine Translation
@article{wu2018study,
  title={A study of reinforcement learning for neural machine translation},
  author={Wu, Lijun and Tian, Fei and Qin, Tao and Lai, Jianhuang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1808.08866},
  year={2018}
}
% RL for RTS games
@inproceedings{andersen2018deep,
  title={Deep RTS: a game environment for deep reinforcement learning in real-time strategy games},
  author={Andersen, Per-Arne and Goodwin, Morten and Granmo, Ole-Christoffer},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}
% RL for Game Development
@inproceedings{andrade2005extending,
  title={Extending reinforcement learning to provide dynamic game balancing},
  author={Andrade, Gustavo and Ramalho, Geber and Santana, Hugo and Corruble, Vincent},
  booktitle={Proceedings of the Workshop on Reasoning, Representation, and Learning in Computer Games, 19th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={7--12},
  year={2005}
}
% Baxter Robot
@inproceedings{fitzgerald2013developing,
  title={Developing baxter},
  author={Fitzgerald, Cliff},
  booktitle={2013 IEEE Conference on Technologies for Practical Robot Applications (TePRA)},
  pages={1--6},
  year={2013},
  organization={IEEE}
}
% Door opening RL
@inproceedings{Shi2017,
title	= {Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates},
author	= {ShiXiang Gu and Ethan Holly and Timothy Lillicrap and Sergey Levine},
year	= {2017},
URL	= {https://arxiv.org/abs/1610.00633}
}
% RL in weather
@inproceedings{kuremoto2007forecasting,
  title={Forecasting time series by SOFNN with reinforcement learning},
  author={Kuremoto, Takashi and Obayashi, Masanao and Kobayashi, Kunikazu},
  booktitle={Proceedings of the 27th Annual International Symposium on Forecasting, Neural Forecasting Competition (NN3), New York, NY, USA},
  pages={24--27},
  year={2007}
}
% RL in trade
@inproceedings{nevmyvaka2006reinforcement,
  title={Reinforcement learning for optimized trade execution},
  author={Nevmyvaka, Yuriy and Feng, Yi and Kearns, Michael},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={673--680},
  year={2006},
  organization={ACM}
}
% RL in biology
@article{neftci2002reinforcement,
  title={Reinforcement learning in artificial and biological systems},
  author={Neftci, Emre O and Averbeck, Bruno B},
  journal={Environment},
  pages={3},
  year={2002}
}
% RL in NLP
@article{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Galley, Michel and Gao, Jianfeng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1606.01541},
  year={2016}
}
% RL in Computational Optimization
@inproceedings{rao2009vconf,
  title={VCONF: a reinforcement learning approach to virtual machines auto-configuration},
  author={Rao, Jia and Bu, Xiangping and Xu, Cheng-Zhong and Wang, Leyi and Yin, George},
  booktitle={Proceedings of the 6th international conference on Autonomic computing},
  pages={137--146},
  year={2009},
  organization={ACM}
}


% ***** Software ******
% Gazebo
@inproceedings{koenig2004design,
  title={Design and use paradigms for gazebo, an open-source multi-robot simulator},
  author={Koenig, Nathan and Howard, Andrew},
  booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566)},
  volume={3},
  pages={2149--2154},
  year={2004},
  organization={IEEE}
}
% OpenAI Gym
@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}
% OpenAI Baselines
@article{dhariwal2017openai,
  title={Openai baselines},
  author={Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  journal={GitHub, GitHub repository},
  year={2017}
}
% TensorFlow
@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}
% ROS
@inproceedings{quigley2009ros,
  title={ROS: an open-source Robot Operating System},
  author={Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y},
  booktitle={ICRA workshop on open source software},
  volume={3},
  number={3.2},
  pages={5},
  year={2009},
  organization={Kobe, Japan}
}
%***** Feature Selection *****
% Survey in Machine Learning Feature Selection and Extraction
@inproceedings{khalid2014survey,
  title={A survey of feature selection and feature extraction techniques in machine learning},
  author={Khalid, Samina and Khalil, Tehmina and Nasreen, Shamila},
  booktitle={2014 Science and Information Conference},
  pages={372--378},
  year={2014},
  organization={IEEE}
}
% RL Feature Selection
@article{liu2015feature,
  title={Feature selection and feature learning for high-dimensional batch reinforcement learning: A survey},
  author={Liu, De-Rong and Li, Hong-Liang and Wang, Ding},
  journal={International Journal of Automation and Computing},
  volume={12},
  number={3},
  pages={229--242},
  year={2015},
  publisher={Springer}
}
%***** Reward Signals *****
% reward-shaping
@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}
%***** Inverse RL *******
% Apprentice learning
@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004},
  organization={ACM}
}
%******* Other Information ********
% Algorithmic Stability
@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={Journal of machine learning research},
  volume={2},
  number={Mar},
  pages={499--526},
  year={2002}
}


